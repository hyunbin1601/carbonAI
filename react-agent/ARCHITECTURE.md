# ğŸ“‹ CarbonAI React-Agent ì „ì²´ ì½”ë“œ ìƒì„¸ ì„¤ëª…

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
LangGraph (graph.py)
    â”œâ”€> call_model (Claude API í˜¸ì¶œ)
    â”‚   â”œâ”€> ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (prompts.py)
    â”‚   â”œâ”€> ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
    â”‚   â””â”€> ë„êµ¬ ì„ íƒ (tool_calls)
    â”‚
    â”œâ”€> tools (ë„êµ¬ ì‹¤í–‰)
    â”‚   â”œâ”€> search_knowledge_base (RAG)
    â”‚   â”‚   â””â”€> rag_tool.py (Chroma DB ë²¡í„° ê²€ìƒ‰)
    â”‚   â”‚
    â”‚   â”œâ”€> classify_customer_segment (ê³ ê° ë¶„ë¥˜)
    â”‚   â”‚
    â”‚   â”œâ”€> search (Tavily ì›¹ ê²€ìƒ‰)
    â”‚   â”‚
    â”‚   â””â”€> MCP ë„êµ¬ (19ê°œ)
    â”‚       â””â”€> sse_mcp_client.py
    â”‚           â”œâ”€> SSE ë¦¬ìŠ¤ë„ˆ (ì‘ë‹µ ìˆ˜ì‹ )
    â”‚           â””â”€> POST ìš”ì²­ (ëª…ë ¹ ì „ì†¡)
    â”‚
    â”œâ”€> Cache (cache_manager.py)
    â”‚   â”œâ”€> Redis (ì„ íƒ)
    â”‚   â””â”€> Memory (ê¸°ë³¸)
    â”‚
    â””â”€> Mermaid ë³€í™˜ (utils.py)
        â””â”€> kroki.io API
```

---

## ğŸ“ íŒŒì¼ë³„ ìƒì„¸ ì„¤ëª…

### 1. **state.py** - ëŒ€í™” ìƒíƒœ ê´€ë¦¬

```python
@dataclass
class InputState:
    messages: Annotated[Sequence[AnyMessage], add_messages]
```

**ì—­í• **: LangGraphì˜ ìƒíƒœ(state)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

**í•µì‹¬ ê°œë…**:
- `messages`: ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì €ì¥
- `add_messages`: LangGraphì˜ íŠ¹ìˆ˜ ì–´ë…¸í…Œì´ì…˜ìœ¼ë¡œ, ë©”ì‹œì§€ë¥¼ "ì¶”ê°€"í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸
- ë©”ì‹œì§€ íŒ¨í„´:
  1. `HumanMessage` - ì‚¬ìš©ì ì…ë ¥
  2. `AIMessage + tool_calls` - AIê°€ ë„êµ¬ ì„ íƒ
  3. `ToolMessage` - ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
  4. `AIMessage` - ìµœì¢… ë‹µë³€
  5. (ë°˜ë³µ)

```python
@dataclass
class State(InputState):
    is_last_step: IsLastStep = field(default=False)
```

**ì¶”ê°€ ìƒíƒœ**:
- `is_last_step`: recursion_limitì— ë„ë‹¬í–ˆëŠ”ì§€ í‘œì‹œí•˜ëŠ” ê´€ë¦¬ ë³€ìˆ˜

---

### 2. **configuration.py** - ì„¤ì • ê´€ë¦¬

```python
@dataclass(kw_only=True)
class Configuration:
    system_prompt: str = prompts.SYSTEM_PROMPT
    model: str = "claude-haiku-4-5-20251001"
    max_search_results: int = 10
    category: Optional[str] = None  # íƒ„ì†Œë°°ì¶œê¶Œ/ê·œì œëŒ€ì‘/ê³ ê°ìƒë‹´
```

**ì—­í• **: ì—ì´ì „íŠ¸ì˜ ì„¤ì •ì„ ì •ì˜í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤

**ì£¼ìš” ì„¤ì •**:
1. `system_prompt`: AIì˜ í–‰ë™ ì§€ì¹¨ (prompts.pyì—ì„œ ê°€ì ¸ì˜´)
2. `model`: ì‚¬ìš©í•  Claude ëª¨ë¸
3. `max_search_results`: ì›¹ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
4. **`category`**: ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ë‹µë³€ (ì¤‘ìš”!)
   - `íƒ„ì†Œë°°ì¶œê¶Œ`: ë°°ì¶œê¶Œ ê±°ë˜, NET-Z í”Œë«í¼
   - `ê·œì œëŒ€ì‘`: Scope ë°°ì¶œëŸ‰, ë²•ê·œ, ë³´ê³ ì„œ
   - `ê³ ê°ìƒë‹´`: ì„œë¹„ìŠ¤ ì•ˆë‚´, ì†”ë£¨ì…˜ ì œì•ˆ

**íŒ©í† ë¦¬ ë©”ì„œë“œ**:
```python
@classmethod
def from_runnable_config(cls, config: RunnableConfig):
    # RunnableConfigì—ì„œ Configuration ê°ì²´ ìƒì„±
    configurable = config.get("configurable") or {}
    return cls(**{k: v for k, v in configurable.items() if k in _fields})
```

---

### 3. **prompts.py** - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸

```python
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í›„ì‹œíŒŒíŠ¸ë„ˆìŠ¤ì˜ íƒ„ì†Œ ë°°ì¶œê¶Œ ì „ë¬¸ ìƒë‹´ AI ì–´ì‹œìŠ¤í„´íŠ¸ "CarbonAI"ì…ë‹ˆë‹¤.

**ì£¼ìš” ì—­í• :**
- íƒ„ì†Œ ë°°ì¶œê¶Œ ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€
- íšŒì‚¬ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µ
- ê³ ê° ìœ í˜•ë³„ ë§ì¶¤í˜• ìƒë‹´ ì œê³µ
```

**ì—­í• **: Claudeê°€ ë”°ë¥¼ í–‰ë™ ì§€ì¹¨

**ì£¼ìš” êµ¬ì„±**:
1. **ì—­í•  ì •ì˜**: íƒ„ì†Œ ë°°ì¶œê¶Œ ì „ë¬¸ ìƒë‹´ AI
2. **ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì„¤ëª…**:
   - `search_knowledge_base`: ë²¡í„° ê²€ìƒ‰
   - `classify_customer_segment`: ê³ ê° ë¶„ë¥˜
   - `search`: ì›¹ ê²€ìƒ‰
   - MCP ë„êµ¬ë“¤ (ìë™ìœ¼ë¡œ ì¶”ê°€ë¨)

3. **Mermaid ë‹¤ì´ì–´ê·¸ë¨ í™œìš© ê°€ì´ë“œ**:
   ```
   - flowchart: í”„ë¡œì„¸ìŠ¤/ì ˆì°¨
   - sequenceDiagram: ì‹œìŠ¤í…œ ìƒí˜¸ì‘ìš©
   - stateDiagram: ìƒíƒœ ë³€í™”
   - gantt: ì¼ì •
   - pie: ë¹„ìœ¨
   ```

4. **ë‹µë³€ ê·œì¹™**:
   - ë¨¼ì € ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
   - ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€
   - ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤
   - ì¶œì²˜ ëª…ì‹œ
   - Mermaid ì ê·¹ í™œìš©

5. **ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤ ë‹µë³€**:
   - ë°°ì¶œê¶Œ_ë³´ìœ ì: í™œìš© ë°©ë²•, íŒë§¤ ì „ëµ
   - ë°°ì¶œê¶Œ_êµ¬ë§¤ì: êµ¬ë§¤ ì ˆì°¨, ê°€ê²© ì •ë³´
   - ë°°ì¶œê¶Œ_íŒë§¤ì: íŒë§¤ ì±„ë„, ì‹œì¥ ë¶„ì„
   - ë°°ì¶œê¶Œ_ìƒì„±_í¬ë§ì: í”„ë¡œì íŠ¸ ê°œë°œ
   - ì¼ë°˜: ê¸°ë³¸ ê°œë…, í”Œë«í¼ ì†Œê°œ

---

### 4. **utils.py** - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

#### 4.1 ë©”ì‹œì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ

```python
def get_message_text(msg: BaseMessage) -> str:
    """ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    content = msg.content
    if isinstance(content, str):
        return content
    elif isinstance(content, dict):
        return content.get("text", "")
    else:
        # ë©€í‹°ëª¨ë‹¬ (ë¦¬ìŠ¤íŠ¸)
        txts = [c if isinstance(c, str) else (c.get("text") or "") for c in content]
        return "".join(txts).strip()
```

#### 4.2 Mermaid â†’ ì´ë¯¸ì§€ ë³€í™˜ (í•µì‹¬!)

```python
def mermaid_to_image_url(mermaid_code: str, output_format: str = "svg") -> str:
    """Mermaid ì½”ë“œë¥¼ kroki.io APIë¡œ ì´ë¯¸ì§€ URL ìƒì„±"""
    # 1. zlibìœ¼ë¡œ ì••ì¶•
    compressed = zlib.compress(mermaid_code.encode('utf-8'), level=9)

    # 2. base64 URL-safe ì¸ì½”ë”©
    encoded = base64.urlsafe_b64encode(compressed).decode('ascii')

    # 3. kroki.io URL ìƒì„±
    url = f"https://kroki.io/mermaid/{output_format}/{encoded}"
    return url
```

**ì™œ ì´ë ‡ê²Œ í•˜ë‚˜?**:
- Claudeê°€ Mermaid ì½”ë“œë¥¼ ì¶œë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ì´ë¯¸ì§€ë¡œ ë³€í™˜
- ì‚¬ìš©ìê°€ ì‹œê°ì ìœ¼ë¡œ ë³´ê¸° ì¢‹ìŒ
- kroki.ioëŠ” ë¬´ë£Œ ë‹¤ì´ì–´ê·¸ë¨ ë Œë”ë§ ì„œë¹„ìŠ¤

```python
def detect_and_convert_mermaid(content: str) -> str:
    """
    ```mermaid ... ``` íŒ¨í„´ì„ ì°¾ì•„ì„œ
    ![Mermaid Diagram](kroki_url) ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    """
    mermaid_blocks = extract_mermaid_blocks(content)

    for full_match, mermaid_code, start_pos, end_pos in reversed(mermaid_blocks):
        image_url = mermaid_to_image_url(mermaid_code)
        markdown_image = f"![{diagram_type}]({image_url})"
        result = result[:start_pos] + markdown_image + result[end_pos:]

    return result
```

---

### 5. **cache_manager.py** - ìºì‹œ ê´€ë¦¬

#### 5.1 ìºì‹œ êµ¬ì¡°

```python
class CacheManager:
    def __init__(self, redis_url=None, default_ttl=86400, use_redis=True):
        self._redis_client = None  # Redis í´ë¼ì´ì–¸íŠ¸
        self._memory_cache: Dict[str, tuple[Any, datetime]] = {}  # ë©”ëª¨ë¦¬ ìºì‹œ
```

**2ë‹¨ê³„ ìºì‹±**:
1. **Redis** (ì„ íƒì ): ë¶„ì‚° í™˜ê²½ì—ì„œ ê³µìœ  ìºì‹œ
2. **Memory** (ê¸°ë³¸): ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ë‚´ ë¹ ë¥¸ ìºì‹œ

#### 5.2 ìºì‹œ í‚¤ ìƒì„±

```python
def _generate_cache_key(self, prefix: str, content: str) -> str:
    """SHA256 í•´ì‹œ ê¸°ë°˜ ìºì‹œ í‚¤"""
    content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()[:16]
    return f"{prefix}:{content_hash}"
```

**ì˜ˆì‹œ**:
- `rag:a1b2c3d4e5f6g7h8` - RAG ê²€ìƒ‰ ê²°ê³¼
- `llm:9i8j7k6l5m4n3o2p` - LLM ì‘ë‹µ

#### 5.3 ìºì‹œ ì‚¬ìš© í”Œë¡œìš°

```python
# 1. ìºì‹œ ì¡°íšŒ
cached = cache_manager.get("rag", query)
if cached:
    return cached  # ìºì‹œ HIT

# 2. ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
result = expensive_operation(query)

# 3. ìºì‹œ ì €ì¥ (24ì‹œê°„)
cache_manager.set("rag", query, result, ttl=86400)
```

**ì¥ì **:
- ë™ì¼í•œ ì§ˆë¬¸ì— ì¦‰ì‹œ ì‘ë‹µ
- LLM API ë¹„ìš© ì ˆê°
- ë²¡í„° ê²€ìƒ‰ ë¶€í•˜ ê°ì†Œ

---

### 6. **rag_tool.py** - RAG ê²€ìƒ‰ ë„êµ¬

#### 6.1 ì´ˆê¸°í™”

```python
class RAGTool:
    def __init__(self, knowledge_base_path=None, chroma_db_path=None):
        # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
        self.embeddings = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",  # í•œêµ­ì–´ íŠ¹í™”
            model_kwargs={'device': 'cpu'}
        )

        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° (ì²­í‚¹)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # 1000ì ë‹¨ìœ„
            chunk_overlap=200  # 200ì ê²¹ì¹¨
        )

        # ë²¡í„° ìŠ¤í† ì–´ (ì§€ì—° ë¡œë”©)
        self._vectorstore: Optional[Chroma] = None
```

**ì„ë² ë”© ëª¨ë¸ ì„ íƒ ì´ìœ **:
- `jhgan/ko-sroberta-multitask`: í•œêµ­ì–´ ë¬¸ì„œì— ìµœì í™”
- ëŒ€ì•ˆ: `sentence-transformers/all-MiniLM-L6-v2` (ì˜ì–´/ë‹¤êµ­ì–´)

#### 6.2 ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹

```python
def _load_documents(self) -> List[Document]:
    """ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    # ì§€ì› íŒŒì¼: .txt, .md, .pdf, .docx
    parsers = {
        '.txt': parse_text_file,
        '.md': parse_text_file,
        '.pdf': parse_pdf,  # pypdf ì‚¬ìš©
        '.docx': parse_docx,  # python-docx ì‚¬ìš©
    }

    for ext, parser_func in parsers.items():
        for file_path in self.knowledge_base_path.rglob(f"*{ext}"):
            # íŒŒì‹±
            content = parser_func(file_path)

            # ì²­í‚¹ (1000ì ë‹¨ìœ„, 200ì ê²¹ì¹¨)
            chunks = self.text_splitter.split_text(content)

            # Document ê°ì²´ ìƒì„±
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        'source': str(file_path),
                        'filename': file_path.name,
                        'chunk_index': i,
                        'total_chunks': len(chunks)
                    }
                )
                documents.append(doc)
```

**ì™œ ì²­í‚¹ì´ í•„ìš”í•œê°€?**:
- ê¸´ ë¬¸ì„œë¥¼ í†µì§¸ë¡œ ì„ë² ë”©í•˜ë©´ ì •ë³´ ì†ì‹¤
- 1000ì ì •ë„ê°€ ì ë‹¹í•œ ë‹¨ìœ„
- 200ì ê²¹ì¹¨ìœ¼ë¡œ ë¬¸ë§¥ ìœ ì§€

#### 6.3 ë²¡í„° DB ìë™ êµ¬ì¶•

```python
def _build_vectorstore_if_needed(self) -> bool:
    """ë²¡í„° DBê°€ ì—†ìœ¼ë©´ ìë™ êµ¬ì¶•"""
    if self.chroma_db_path.exists():
        return False  # ì´ë¯¸ ìˆìŒ

    documents = self._load_documents()

    # Chroma DB ìƒì„±
    self._vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=self.embeddings,
        persist_directory=str(self.chroma_db_path)
    )
```

**ìë™í™”ì˜ ì¥ì **:
- ì²˜ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë²¡í„° DB êµ¬ì¶•
- ì§€ì‹ë² ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ì‹œ ìë™ ê°ì§€ ë° ê°±ì‹ 

#### 6.4 í‚¤ì›Œë“œ ì¶”ì¶œ (ì¤‘ìš”!)

```python
def _extract_keywords(self, query: str) -> str:
    """LLMìœ¼ë¡œ ì¿¼ë¦¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    llm = ChatAnthropic(model="claude-haiku-4-5", temperature=0)

    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì¡°ì‚¬, ì˜ë¬¸ì‚¬, ìš”ì²­ì–´ëŠ” ì œê±°í•˜ê³  ëª…ì‚¬ ìœ„ì£¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
ì¤‘ìš”í•œ í‚¤ì›Œë“œëŠ” ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”. ìµœì†Œ 3-5ê°œ ì´ìƒì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

í•µì‹¬ í‚¤ì›Œë“œ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„, ìµœì†Œ 3ê°œ ì´ìƒ):"""

    response = llm.invoke([HumanMessage(content=prompt)])
    keywords = response.content.strip()
    return keywords
```

**ì™œ í‚¤ì›Œë“œ ì¶”ì¶œì´ í•„ìš”í•œê°€?**:
- ì›ë³¸ ì§ˆë¬¸: "ë°°ì¶œê¶Œì„ êµ¬ë§¤í•˜ë ¤ë©´ ì–´ë–¤ ì ˆì°¨ë¥¼ ê±°ì³ì•¼ í•˜ë‚˜ìš”?"
- í‚¤ì›Œë“œ: "ë°°ì¶œê¶Œ êµ¬ë§¤ ì ˆì°¨"
- ë²¡í„° ê²€ìƒ‰ ì‹œ ë” ì •í™•í•œ ë§¤ì¹­

#### 6.5 ë¬¸ì„œ ê²€ìƒ‰ (í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)

```python
def search_documents(self, query: str, k: int = 3, similarity_threshold: float = 0.5):
    """
    1. ìºì‹œ í™•ì¸
    2. í‚¤ì›Œë“œ ì¶”ì¶œ
    3. ë²¡í„° ê²€ìƒ‰ (í‚¤ì›Œë“œ + ì›ë³¸ ëª¨ë‘)
    4. ìœ ì‚¬ë„ í•„í„°ë§
    5. ì¤‘ë³µ ì œê±°
    6. ìƒìœ„ kê°œ ë°˜í™˜
    7. ê²°ê³¼ ìºì‹±
    """

    # 1. ìºì‹œ í™•ì¸
    cached_result = cache_manager.get("rag", cache_content)
    if cached_result:
        return cached_result

    # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
    keyword_query = self._extract_keywords(query)

    # 3. ë²¡í„° ê²€ìƒ‰ (í‚¤ì›Œë“œ)
    keyword_docs = self.vectorstore.similarity_search_with_score(keyword_query, k=k*3)

    # 4. ë²¡í„° ê²€ìƒ‰ (ì›ë³¸, í‚¤ì›Œë“œì™€ ë‹¤ë¥´ë©´)
    if keyword_query != query:
        original_docs = self.vectorstore.similarity_search_with_score(query, k=k*3)
        all_docs_with_scores.extend(original_docs)

    # 5. ìœ ì‚¬ë„ ì •ë ¬ ë° í•„í„°ë§
    for doc, distance in docs_with_scores:
        similarity = 1.0 - distance  # ì½”ì‚¬ì¸ ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜

        if similarity < similarity_threshold:  # 0.5 ë¯¸ë§Œ ì œì™¸
            continue

        # ì¤‘ë³µ ì œê±°
        doc_key = (source, chunk_index)
        if doc_key in seen_keys:
            continue

        filtered_docs.append({
            'content': doc.page_content,
            'source': source,
            'filename': filename,
            'chunk_index': chunk_index,
            'similarity': similarity
        })

        if len(filtered_docs) >= k:
            break

    # 6. ìºì‹±
    cache_manager.set("rag", cache_content, filtered_docs)
    return filtered_docs
```

**ìœ ì‚¬ë„ ê³„ì‚°**:
- Chroma DBëŠ” L2 ê±°ë¦¬ ë˜ëŠ” ì½”ì‚¬ì¸ ê±°ë¦¬ ì‚¬ìš©
- ê±°ë¦¬ (distance): 0 ~ 2 (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
- ìœ ì‚¬ë„ (similarity): `1.0 - distance`
- ì„ê³„ê°’ 0.5: 50% ì´ìƒ ìœ ì‚¬í•œ ë¬¸ì„œë§Œ ë°˜í™˜

---

### 7. **graph.py** - LangGraph ì›Œí¬í”Œë¡œìš° (í•µì‹¬!)

#### 7.1 ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±

```python
def _get_category_prompt(base_prompt: str, category: str) -> str:
    """ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì¶”ê°€"""
    category_prompts = {
        "íƒ„ì†Œë°°ì¶œê¶Œ": """
**ì¹´í…Œê³ ë¦¬: íƒ„ì†Œë°°ì¶œê¶Œ ì „ë¬¸ ìƒë‹´**

**íŠ¹í™” ë‹µë³€ í¬ì¸íŠ¸:**
- ë°°ì¶œê¶Œ ìœ í˜•ë³„ ìƒì„¸ ì„¤ëª… (KOC, KCU, KAU ë“±)
- ë°°ì¶œê¶Œ ê±°ë˜ ì ˆì°¨ ë° ì‹œì¥ ë™í–¥
- NET-Z í”Œë«í¼ ì‚¬ìš©ë²• ë° ê¸°ëŠ¥
- ë°°ì¶œê¶Œ ê°€ê²© ì •ë³´ ë° ì‹œì¥ ë¶„ì„
- í”„ë¡œì„¸ìŠ¤ëŠ” Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œê°í™”
""",
        "ê·œì œëŒ€ì‘": """
**ì¹´í…Œê³ ë¦¬: ê·œì œëŒ€ì‘ ì „ë¬¸ ìƒë‹´**

**íŠ¹í™” ë‹µë³€ í¬ì¸íŠ¸:**
- Scope 1, 2, 3 ë°°ì¶œëŸ‰ ì¸¡ì • ë°©ë²•
- íƒ„ì†Œ ë°°ì¶œëŸ‰ ë³´ê³  ì˜ë¬´ ë° ì ˆì°¨
- ê·œì œ ë³€ê²½ì‚¬í•­ ë° ëŒ€ì‘ ë°©ì•ˆ
- ESG ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œ
- í”„ë¡œì„¸ìŠ¤ëŠ” Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œê°í™”
""",
        "ê³ ê°ìƒë‹´": """
**ì¹´í…Œê³ ë¦¬: ê³ ê°ìƒë‹´ ì „ë¬¸ ìƒë‹´**

**íŠ¹í™” ë‹µë³€ í¬ì¸íŠ¸:**
- í›„ì‹œíŒŒíŠ¸ë„ˆìŠ¤ ì„œë¹„ìŠ¤ ì†Œê°œ
- ê¸°ì—… ê·œëª¨ë³„ ì¶”ì²œ ì†”ë£¨ì…˜
- ì„œë¹„ìŠ¤ ì´ìš© ì ˆì°¨ ì•ˆë‚´
- ë¹„ìš© ë° ìš”ê¸ˆì œ ì •ë³´
- ë¹„êµëŠ” Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œê°í™”
"""
    }

    category_prompt = category_prompts.get(category, "")
    if category_prompt:
        return base_prompt + "\n\n" + category_prompt
    return base_prompt
```

**íš¨ê³¼**:
- "íƒ„ì†Œë°°ì¶œê¶Œ" ì¹´í…Œê³ ë¦¬: ê±°ë˜ ì¤‘ì‹¬ ë‹µë³€
- "ê·œì œëŒ€ì‘" ì¹´í…Œê³ ë¦¬: ë²•ê·œ/ë³´ê³ ì„œ ì¤‘ì‹¬ ë‹µë³€
- "ê³ ê°ìƒë‹´" ì¹´í…Œê³ ë¦¬: ì„œë¹„ìŠ¤ ì•ˆë‚´ ì¤‘ì‹¬ ë‹µë³€

#### 7.2 LLM ì‘ë‹µ ìºì‹±

```python
def _serialize_messages_for_cache(messages, system_message, category):
    """ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ìºì‹œ í‚¤ë¡œ ì§ë ¬í™”"""
    simplified = []
    for msg in messages:
        if isinstance(msg, (HumanMessage, AIMessage, SystemMessage)):
            simplified.append({
                "type": msg.__class__.__name__,
                "content": str(msg.content)[:500]  # 500ìë§Œ
            })
        elif isinstance(msg, ToolMessage):
            return None  # íˆ´ ë©”ì‹œì§€ ìˆìœ¼ë©´ ìºì‹± ì•ˆ í•¨

    cache_data = {
        "system": system_message[:200],
        "category": category,
        "messages": simplified
    }
    return json.dumps(cache_data, ensure_ascii=False, sort_keys=True)
```

**ì™œ íˆ´ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ìºì‹± ì•ˆ í•˜ë‚˜?**:
- íˆ´ í˜¸ì¶œ ê²°ê³¼ëŠ” ë™ì  (ì‹œê°„ì— ë”°ë¼ ë³€í•¨)
- ì˜ˆ: "ì˜¤ëŠ˜ ë°°ì¶œê¶Œ ê°€ê²©ì€?" â†’ ë§¤ì¼ ë‹¤ë¥¸ ê²°ê³¼

#### 7.3 call_model - LLM í˜¸ì¶œ

```python
async def call_model(state: State, config: RunnableConfig):
    """LLM í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬"""

    # 1. ì„¤ì • ë¡œë“œ
    configuration = Configuration.from_runnable_config(config)

    # 2. MCP ë„êµ¬ í¬í•¨í•œ ì „ì²´ ë„êµ¬ ë¡œë“œ
    all_tools = await get_all_tools()

    # 3. Claude ëª¨ë¸ ì´ˆê¸°í™”
    llm = ChatAnthropic(temperature=0.1, model=configuration.model)
    model = llm.bind_tools(all_tools)  # ë„êµ¬ ë°”ì¸ë”©

    # 4. ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
    base_prompt = configuration.system_prompt
    if configuration.category:
        base_prompt = _get_category_prompt(base_prompt, configuration.category)

    system_message = base_prompt.format(system_time=datetime.now(tz=UTC).isoformat())

    # 5. ìºì‹œ í™•ì¸
    cache_key_content = _serialize_messages_for_cache(
        state.messages, system_message, configuration.category or ""
    )

    if cache_key_content:
        cached_response = cache_manager.get("llm", cache_key_content)
        if cached_response:
            return {"messages": [AIMessage(**cached_response)]}

    # 6. LLM í˜¸ì¶œ
    response = await model.ainvoke([
        {"role": "system", "content": system_message},
        *state.messages
    ])

    # 7. ë§ˆì§€ë§‰ ë‹¨ê³„ì¸ë° ì•„ì§ íˆ´ í˜¸ì¶œí•˜ë ¤ê³  í•˜ë©´ ì¢…ë£Œ
    if state.is_last_step and response.tool_calls:
        return {
            "messages": [AIMessage(
                id=response.id,
                content="Sorry, I could not find an answer to your question in the specified number of steps."
            )]
        }

    # 8. Mermaid ì½”ë“œ ìë™ ë³€í™˜
    if response.content and isinstance(response.content, str):
        converted_content = detect_and_convert_mermaid(response.content)
        if converted_content != response.content:
            response = AIMessage(
                id=response.id,
                content=converted_content,
                tool_calls=response.tool_calls,
                additional_kwargs=response.additional_kwargs,
            )

    # 9. LLM ì‘ë‹µ ìºì‹± (íˆ´ í˜¸ì¶œ ì—†ëŠ” ìµœì¢… ì‘ë‹µë§Œ)
    if cache_key_content and not response.tool_calls:
        cache_data = {
            "content": response.content,
            "additional_kwargs": response.additional_kwargs,
            "id": response.id
        }
        cache_manager.set("llm", cache_key_content, cache_data)

    return {"messages": [response]}
```

#### 7.4 call_tools - ë„êµ¬ ì‹¤í–‰

```python
async def call_tools(state: State):
    """ë™ì ìœ¼ë¡œ ë„êµ¬ ë¡œë“œ ë° ì‹¤í–‰"""
    all_tools = await get_all_tools()  # MCP ë„êµ¬ í¬í•¨
    tool_node = ToolNode(all_tools)
    return await tool_node.ainvoke(state)
```

**ToolNodeë€?**:
- LangGraphì˜ ë‚´ì¥ ë…¸ë“œ
- `state.messages`ì—ì„œ `tool_calls` ì¶”ì¶œ
- í•´ë‹¹ ë„êµ¬ ì‹¤í–‰
- ê²°ê³¼ë¥¼ `ToolMessage`ë¡œ ë°˜í™˜

#### 7.5 ê·¸ë˜í”„ êµ¬ì¶•

```python
# StateGraph ìƒì„±
builder = StateGraph(State, input=InputState, config_schema=Configuration)

# ë…¸ë“œ ì¶”ê°€
builder.add_node(call_model)  # LLM í˜¸ì¶œ
builder.add_node("tools", call_tools)  # ë„êµ¬ ì‹¤í–‰

# ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
builder.add_edge("__start__", "call_model")

# ì¡°ê±´ë¶€ ì—£ì§€
def route_model_output(state: State):
    """LLM ì‘ë‹µì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    last_message = state.messages[-1]

    if not last_message.tool_calls:
        return "__end__"  # íˆ´ í˜¸ì¶œ ì—†ìœ¼ë©´ ì¢…ë£Œ

    return "tools"  # íˆ´ í˜¸ì¶œ ìˆìœ¼ë©´ tools ë…¸ë“œë¡œ

builder.add_conditional_edges("call_model", route_model_output)

# ì‚¬ì´í´ ìƒì„±
builder.add_edge("tools", "call_model")  # íˆ´ ì‹¤í–‰ í›„ ë‹¤ì‹œ LLMìœ¼ë¡œ

# ì»´íŒŒì¼
graph = builder.compile(name="ReAct Agent")
```

**ì‹¤í–‰ íë¦„**:
```
__start__
  â†’ call_model (LLM í˜¸ì¶œ)
     â”œâ”€> íˆ´ í˜¸ì¶œ ì—†ìŒ â†’ __end__
     â””â”€> íˆ´ í˜¸ì¶œ ìˆìŒ â†’ tools
           â†’ call_model
              â”œâ”€> íˆ´ í˜¸ì¶œ ì—†ìŒ â†’ __end__
              â””â”€> íˆ´ í˜¸ì¶œ ìˆìŒ â†’ tools (ë°˜ë³µ)
```

---

### 8. **tools.py** - ë„êµ¬ ì •ì˜ ë° MCP í†µí•©

#### 8.1 ê¸°ë³¸ ë„êµ¬ë“¤

##### 8.1.1 search - Tavily ì›¹ ê²€ìƒ‰

```python
async def search(query: str) -> Optional[dict[str, Any]]:
    """Tavily ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ ì›¹ ê²€ìƒ‰"""
    configuration = Configuration.from_context()
    wrapped = TavilySearch(max_results=configuration.max_search_results)
    return await wrapped.ainvoke({"query": query})
```

**ìš©ë„**: ìµœì‹  ì •ë³´, ì‹œì¥ ê°€ê²© ë“±

##### 8.1.2 search_knowledge_base - RAG ê²€ìƒ‰

```python
@tool
def search_knowledge_base(query: str, k: int = 3):
    """íšŒì‚¬ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

    **ê²€ìƒ‰ ë°©ì‹**:
    - LLMìœ¼ë¡œ ì¿¼ë¦¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    - í‚¤ì›Œë“œì™€ ì›ë³¸ ëª¨ë‘ë¡œ ê²€ìƒ‰
    - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ 0.5 ì´ìƒë§Œ ë°˜í™˜
    - ì¤‘ë³µ ì œê±°

    **ì¤‘ìš”**: queryì—ëŠ” ì „ì²´ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬!
    """
    rag_tool = get_rag_tool()
    results = rag_tool.search_documents(query, k=k, similarity_threshold=0.5)

    if not results:
        return {
            "status": "no_results",
            "message": "ìœ ì‚¬ë„ 0.5 ì´ìƒì¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "results": []
        }

    return {
        "status": "success",
        "message": f"{len(results)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
        "results": results
    }
```

##### 8.1.3 classify_customer_segment - ê³ ê° ë¶„ë¥˜

```python
@tool
def classify_customer_segment(question: str):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜"""
    question_lower = question.lower()

    if any(kw in question_lower for kw in ['ë³´ìœ ', 'ê°€ì§€ê³ ', 'ì†Œìœ ']):
        segment = "ë°°ì¶œê¶Œ_ë³´ìœ ì"
    elif any(kw in question_lower for kw in ['êµ¬ë§¤', 'ì‚¬ê³  ì‹¶']):
        segment = "ë°°ì¶œê¶Œ_êµ¬ë§¤ì"
    elif any(kw in question_lower for kw in ['íŒë§¤', 'íŒ”ê³  ì‹¶']):
        segment = "ë°°ì¶œê¶Œ_íŒë§¤ì"
    elif any(kw in question_lower for kw in ['ìƒì„±', 'ë§Œë“¤', 'í”„ë¡œì íŠ¸']):
        segment = "ë°°ì¶œê¶Œ_ìƒì„±_í¬ë§ì"
    else:
        segment = "ì¼ë°˜"

    return {"segment": segment, "confidence": "high" if segment != "ì¼ë°˜" else "medium"}
```

#### 8.2 MCP í†µí•© (í•µì‹¬!)

##### 8.2.1 MCP í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬

```python
_netz_mcp_client: Optional[SSEMCPClient] = None

async def _get_mcp_client():
    """MCP í´ë¼ì´ì–¸íŠ¸ lazy ì´ˆê¸°í™” ë° ìë™ ì¬ì—°ê²°"""
    global _netz_mcp_client

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    netz_enabled = os.getenv("NETZ_MCP_ENABLED", "false").lower() == "true"
    netz_url = os.getenv("NETZ_MCP_URL")

    if not netz_enabled or not netz_url:
        return None

    # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ìƒíƒœ í™•ì¸
    if _netz_mcp_client is not None:
        # SSE ë¦¬ìŠ¤ë„ˆê°€ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸
        if (_netz_mcp_client.running and
            _netz_mcp_client.sse_task and
            not _netz_mcp_client.sse_task.done()):
            return _netz_mcp_client  # ì •ìƒ ë™ì‘ ì¤‘
        else:
            # ì—°ê²° ëŠì–´ì§ â†’ ì¬ì´ˆê¸°í™”
            logger.warning("[NET-Z MCP] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§, ì¬ì´ˆê¸°í™” ì¤‘...")
            await _netz_mcp_client.close()
            _netz_mcp_client = None

    # ìƒˆ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    try:
        _netz_mcp_client = SSEMCPClient(base_url=netz_url)
        await _netz_mcp_client.initialize()
        logger.info("[NET-Z MCP] âœ“ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        return _netz_mcp_client
    except Exception as e:
        logger.error(f"[NET-Z MCP] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        _netz_mcp_client = None
        return None
```

**ìë™ ì¬ì—°ê²° ë¡œì§**:
1. SSE ë¦¬ìŠ¤ë„ˆ ìƒíƒœ í™•ì¸
2. ëŠì–´ì¡Œìœ¼ë©´ ìë™ ì¬ì—°ê²°
3. ì‹¤íŒ¨í•´ë„ ì—ëŸ¬ ì•ˆ ëƒ„ (None ë°˜í™˜)

##### 8.2.2 MCP ë„êµ¬ ë³€í™˜ (í•µì‹¬!)

```python
def _create_mcp_tool(mcp_tool_def: Dict[str, Any]):
    """MCP ë„êµ¬ ì •ì˜ â†’ LangChain ë„êµ¬ ë³€í™˜"""

    tool_name = mcp_tool_def["name"]
    tool_description = mcp_tool_def.get("description", "")
    input_schema = mcp_tool_def.get("inputSchema", {})

    # ë™ì  í•¨ìˆ˜ ìƒì„±
    async def mcp_tool_wrapper(**kwargs):
        max_retries = 2
        for attempt in range(max_retries):
            try:
                client = await _get_mcp_client()

                if client is None:
                    return "ì˜¤ë¥˜: NET-Z MCP ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                # MCP ë„êµ¬ í˜¸ì¶œ
                result = await client.call_tool(tool_name, kwargs)

                # ê²°ê³¼ íŒŒì‹± (dataë§Œ ì§ì ‘ ë°˜í™˜)
                content = result.get("content", [])
                if content and len(content) > 0:
                    text_content = content[0].get("text", "{}")
                    data = json.loads(text_content) if isinstance(text_content, str) else text_content
                    return data  # {"year": "2025", "totalEmission": "31.743", ...}

                return result

            except Exception as e:
                # ì¬ì‹œë„ ë¡œì§
                if attempt < max_retries - 1:
                    # í´ë¼ì´ì–¸íŠ¸ ì¬ì„¤ì •
                    global _netz_mcp_client
                    if _netz_mcp_client:
                        await _netz_mcp_client.close()
                        _netz_mcp_client = None
                    await asyncio.sleep(0.5)
                else:
                    return f"ì˜¤ë¥˜: MCP ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)}"

    mcp_tool_wrapper.__name__ = tool_name
    mcp_tool_wrapper.__doc__ = tool_description

    # Pydantic ìŠ¤í‚¤ë§ˆ ìƒì„± (íŒŒë¼ë¯¸í„° ì´ë¦„ ë³´ì¡´!)
    properties = input_schema.get("properties", {})
    required_fields = input_schema.get("required", [])

    fields = {}
    for param_name, param_info in properties.items():
        param_type = param_info.get("type", "string")
        param_desc = param_info.get("description", "")

        # íƒ€ì… ë³€í™˜
        python_type = {
            "string": str,
            "integer": int,
            "number": float,
            "boolean": bool
        }.get(param_type, Any)

        # í•„ìˆ˜/ì„ íƒ êµ¬ë¶„
        if param_name in required_fields:
            fields[param_name] = (python_type, Field(description=param_desc))
        else:
            fields[param_name] = (python_type, Field(default=None, description=param_desc))

    # Pydantic ëª¨ë¸ ìƒì„±
    if fields:
        ArgsSchema = create_model(f"{tool_name}Schema", **fields)
        return tool(args_schema=ArgsSchema)(mcp_tool_wrapper)
    else:
        return tool(mcp_tool_wrapper)
```

**í•µì‹¬ í¬ì¸íŠ¸**:

1. **íŒŒë¼ë¯¸í„° ì´ë¦„ ë³´ì¡´**:
   - MCP ì„œë²„: `enterpriseName` (ì¹´ë©œì¼€ì´ìŠ¤)
   - Pydantic ìŠ¤í‚¤ë§ˆ: `enterpriseName` (ê·¸ëŒ€ë¡œ ìœ ì§€)
   - Claude: `enterpriseName`ë¡œ í˜¸ì¶œ

2. **ë°˜í™˜ ê°’ ë‹¨ìˆœí™”**:
   - MCP ì‘ë‹µ: `{"content": [{"text": "{...}"}]}`
   - LangChain ë°˜í™˜: `{...}` (ë°ì´í„°ë§Œ)

3. **ì¬ì‹œë„ ë¡œì§**:
   - ì—°ê²° ì‹¤íŒ¨ ì‹œ 2íšŒê¹Œì§€ ì¬ì‹œë„
   - ì‹¤íŒ¨í•´ë„ ì—ëŸ¬ ë¬¸ìì—´ ë°˜í™˜ (ì˜ˆì™¸ ì•ˆ ëƒ„)

##### 8.2.3 MCP ë„êµ¬ ë¡œë“œ

```python
async def _load_mcp_tools():
    """MCP ì„œë²„ì—ì„œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì™€ LangChain ë„êµ¬ë¡œ ë³€í™˜"""
    global _mcp_tools_cache, _mcp_tools_loaded

    # ìºì‹œ í™•ì¸
    if _mcp_tools_loaded and _mcp_tools_cache is not None:
        return _mcp_tools_cache

    mcp_tools = []

    try:
        client = await _get_mcp_client()

        if client is None:
            logger.warning("[NET-Z MCP] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            _mcp_tools_loaded = True
            _mcp_tools_cache = []
            return []

        # ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        tools_list = await client.list_tools()
        logger.info(f"[NET-Z MCP] {len(tools_list)}ê°œ ë„êµ¬ ë°œê²¬")

        # ê° MCP ë„êµ¬ë¥¼ LangChain ë„êµ¬ë¡œ ë³€í™˜
        for mcp_tool in tools_list:
            try:
                langchain_tool = _create_mcp_tool(mcp_tool)
                mcp_tools.append(langchain_tool)
                logger.info(f"  âœ“ {mcp_tool['name']}")
            except Exception as e:
                logger.error(f"  âœ— {mcp_tool['name']} ë¡œë“œ ì‹¤íŒ¨: {e}")

        _mcp_tools_cache = mcp_tools
        _mcp_tools_loaded = True

        logger.info(f"[NET-Z MCP] âœ“ {len(mcp_tools)}ê°œ ë„êµ¬ ë¡œë“œ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"[NET-Z MCP] ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        _mcp_tools_loaded = True
        _mcp_tools_cache = []

    return mcp_tools
```

##### 8.2.4 ì „ì²´ ë„êµ¬ ë°˜í™˜

```python
async def get_all_tools():
    """ê¸°ë³¸ ë„êµ¬ + MCP ë„êµ¬ ë°˜í™˜"""

    # MCP ë„êµ¬ ë¡œë“œ (ìºì‹œë¨)
    mcp_tools = await _load_mcp_tools()

    # ì „ì²´ ë„êµ¬ ëª©ë¡
    all_tools = _BASE_TOOLS + mcp_tools

    logger.info(f"[ë„êµ¬ ëª©ë¡] ì´ {len(all_tools)}ê°œ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥:")
    logger.info(f"  - ê¸°ë³¸ ë„êµ¬: {len(_BASE_TOOLS)}ê°œ")
    logger.info(f"  - NET-Z MCP ë„êµ¬: {len(mcp_tools)}ê°œ")

    return all_tools
```

**ê²°ê³¼**:
- ê¸°ë³¸ ë„êµ¬: 3ê°œ (search, search_knowledge_base, classify_customer_segment)
- NET-Z MCP ë„êµ¬: 19ê°œ
- ì´: 22ê°œ ë„êµ¬

---

### 9. **sse_mcp_client.py** - SSE ê¸°ë°˜ MCP í´ë¼ì´ì–¸íŠ¸

#### 9.1 MCP í”„ë¡œí† ì½œ ì´í•´

**MCP (Model Context Protocol)**:
- ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ì•„í‚¤í…ì²˜
- JSON-RPC 2.0 ê¸°ë°˜
- SSE (Server-Sent Events)ë¡œ ì–‘ë°©í–¥ í†µì‹ 

**í†µì‹  ë°©ì‹**:
```
í´ë¼ì´ì–¸íŠ¸                    ì„œë²„
    |                           |
    | GET /mcp/sse              |
    |-------------------------->|
    |                           |
    | <-- SSE ìŠ¤íŠ¸ë¦¼ ì‹œì‘       |
    | event: endpoint           |
    | data: /mcp/message?sessionId=xxx
    |                           |
    | POST /mcp/message         |
    | {"method": "initialize"}  |
    |-------------------------->|
    |                           |
    | (SSEë¡œ ì‘ë‹µ ìˆ˜ì‹ )         |
    | event: message            |
    | data: {"result": {...}}   |
    | <-------------------------|
```

#### 9.2 í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡°

```python
class SSEMCPClient:
    def __init__(self, base_url: str, api_key: Optional[str] = None):
        self.base_url = base_url
        self.api_key = api_key
        self.session_id = None
        self.request_id = 0

        # ë°±ê·¸ë¼ìš´ë“œ SSE ë¦¬ìŠ¤ë„ˆ
        self.sse_task: Optional[asyncio.Task] = None
        self.sse_client: Optional[httpx.AsyncClient] = None

        # ìš”ì²­-ì‘ë‹µ ë§¤ì¹­
        self.pending_requests: Dict[int, asyncio.Future] = {}
        self.running = False
```

**í•µì‹¬ êµ¬ì„± ìš”ì†Œ**:
1. `sse_task`: ë°±ê·¸ë¼ìš´ë“œì—ì„œ SSE ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹ 
2. `pending_requests`: ìš”ì²­ ID â†’ Future ë§¤í•‘
3. `running`: SSE ë¦¬ìŠ¤ë„ˆ ì‹¤í–‰ ìƒíƒœ

#### 9.3 SSE ë¦¬ìŠ¤ë„ˆ (ë°±ê·¸ë¼ìš´ë“œ)

```python
async def _sse_listener(self):
    """ë°±ê·¸ë¼ìš´ë“œ SSE ë¦¬ìŠ¤ë„ˆ (ì‘ë‹µ ìˆ˜ì‹ )"""

    headers = {
        "Accept": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive"
    }

    self.sse_client = httpx.AsyncClient(timeout=None)

    async with self.sse_client.stream("GET", f"{self.base_url}/mcp/sse", headers=headers) as response:
        logger.info("[SSE-MCP] SSE ìŠ¤íŠ¸ë¦¼ ì—°ê²°ë¨")

        current_event = None

        async for line in response.aiter_lines():
            if not self.running:
                break

            line = line.strip()
            if not line:
                continue

            # event: í•„ë“œ
            if line.startswith("event:"):
                current_event = line[6:].strip()
                continue

            # data: í•„ë“œ
            if line.startswith("data:"):
                data_str = line[5:].strip()

                # endpoint ì´ë²¤íŠ¸: ì„¸ì…˜ ID ì¶”ì¶œ
                if current_event == "endpoint" and "sessionId=" in data_str:
                    self.session_id = data_str.split("sessionId=")[1].split("&")[0]
                    logger.info(f"[SSE-MCP] ì„¸ì…˜ ID íšë“: {self.session_id}")
                    continue

                # message ì´ë²¤íŠ¸: JSON-RPC ì‘ë‹µ
                if current_event == "message":
                    msg = json.loads(data_str)

                    # ping ë¬´ì‹œ
                    if msg.get("method") == "ping":
                        continue

                    # ì‘ë‹µ ë§¤ì¹­
                    msg_id = msg.get("id")
                    if msg_id and msg_id in self.pending_requests:
                        future = self.pending_requests.pop(msg_id)

                        if "error" in msg:
                            future.set_exception(Exception(f"MCP Error: {msg['error']}"))
                        else:
                            future.set_result(msg.get("result", {}))
```

**ë™ì‘ ì›ë¦¬**:
1. SSE ìŠ¤íŠ¸ë¦¼ ì—°ê²° ìœ ì§€
2. `event:` ë¼ì¸ì—ì„œ ì´ë²¤íŠ¸ íƒ€ì… ì½ê¸°
3. `data:` ë¼ì¸ì—ì„œ ë°ì´í„° ì½ê¸°
4. ì´ë²¤íŠ¸ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬:
   - `endpoint`: ì„¸ì…˜ ID ì¶”ì¶œ
   - `message`: JSON-RPC ì‘ë‹µ íŒŒì‹± ë° Future ì™„ë£Œ

#### 9.4 ì´ˆê¸°í™”

```python
async def initialize(self):
    """MCP ì„œë²„ ì´ˆê¸°í™”"""

    # 1ë‹¨ê³„: SSE ë¦¬ìŠ¤ë„ˆ ì‹œì‘
    self.running = True
    self.sse_task = asyncio.create_task(self._sse_listener())

    # ì„¸ì…˜ ID íšë“ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
    for _ in range(50):
        if self.session_id:
            break
        await asyncio.sleep(0.1)

    if not self.session_id:
        raise Exception("ì„¸ì…˜ ID íšë“ ì‹¤íŒ¨")

    # 2ë‹¨ê³„: initialize ë©”ì‹œì§€ ì „ì†¡
    request = {
        "jsonrpc": "2.0",
        "id": self._next_id(),
        "method": "initialize",
        "params": {
            "protocolVersion": "2024-11-05",
            "capabilities": {},
            "clientInfo": {"name": "carbon-ai", "version": "1.0.0"}
        }
    }

    result = await self._send_request(request)

    # 3ë‹¨ê³„: initialized ì•Œë¦¼ ì „ì†¡ (MCP í”„ë¡œí† ì½œ í•„ìˆ˜!)
    notification = {
        "jsonrpc": "2.0",
        "method": "notifications/initialized"
    }

    async with httpx.AsyncClient(timeout=5.0) as client:
        url = f"{self.base_url}/mcp/message?sessionId={self.session_id}"
        await client.post(url, json=notification, headers=self._get_headers())

    logger.info("[SSE-MCP] ì´ˆê¸°í™” ì™„ë£Œ")
    return result
```

**ì™œ initialized ì•Œë¦¼ì´ í•„ìš”í•œê°€?**:
- MCP í”„ë¡œí† ì½œ ê·œê²© (3-way handshake)
- ì„œë²„ê°€ ì´ ì•Œë¦¼ì„ ë°›ê¸° ì „ê¹Œì§€ ë‹¤ë¥¸ ìš”ì²­ ì²˜ë¦¬ ì•ˆ í•¨

#### 9.5 ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°

```python
async def _send_request(self, request: Dict[str, Any], timeout: float = 10.0):
    """ìš”ì²­ ì „ì†¡ ë° SSEë¡œ ì‘ë‹µ ëŒ€ê¸°"""

    req_id = request["id"]

    # SSE ë¦¬ìŠ¤ë„ˆ ìƒíƒœ í™•ì¸ (ëŠì–´ì¡Œìœ¼ë©´ ì¬ì‹œì‘)
    if not self.running or not self.sse_task or self.sse_task.done():
        logger.warning("[SSE-MCP] SSE ë¦¬ìŠ¤ë„ˆ ì¬ì‹œì‘ ì¤‘...")
        self.running = True
        self.sse_task = asyncio.create_task(self._sse_listener())
        await asyncio.sleep(0.5)

    # Future ìƒì„±
    future = asyncio.Future()
    self.pending_requests[req_id] = future

    try:
        # POST ìš”ì²­ ì „ì†¡ (ì‘ë‹µ ë³¸ë¬¸ì€ ë¹„ì–´ìˆìŒ)
        async with httpx.AsyncClient(timeout=30.0) as client:
            url = f"{self.base_url}/mcp/message?sessionId={self.session_id}"

            response = await client.post(url, json=request, headers=self._get_headers())

            if response.status_code != 200:
                raise Exception(f"Request failed: {response.status_code}")

        # SSEë¡œ ì‘ë‹µì´ ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
        result = await asyncio.wait_for(future, timeout=timeout)
        return result

    except asyncio.TimeoutError:
        self.pending_requests.pop(req_id, None)
        raise Exception(f"Request timeout (ID={req_id})")
```

**ë™ì‘ í”Œë¡œìš°**:
1. Future ìƒì„± ë° `pending_requests`ì— ë“±ë¡
2. POST ìš”ì²­ ì „ì†¡ (ë³¸ë¬¸ì€ ë¹„ì–´ìˆìŒ, 200 OKë§Œ ë°›ìŒ)
3. SSE ë¦¬ìŠ¤ë„ˆê°€ ì‘ë‹µ ìˆ˜ì‹ í•  ë•Œê¹Œì§€ Future ëŒ€ê¸°
4. SSE ë¦¬ìŠ¤ë„ˆê°€ `future.set_result()` í˜¸ì¶œ
5. Future ì™„ë£Œ, ê²°ê³¼ ë°˜í™˜

#### 9.6 ë„êµ¬ í˜¸ì¶œ

```python
async def call_tool(self, tool_name: str, arguments: Dict[str, Any], timeout: float = 30.0):
    """ë„êµ¬ í˜¸ì¶œ"""

    if not self.session_id:
        await self.initialize()

    request = {
        "jsonrpc": "2.0",
        "id": self._next_id(),
        "method": "tools/call",
        "params": {
            "name": tool_name,
            "arguments": arguments
        }
    }

    result = await self._send_request(request, timeout=timeout)
    return result
```

**ê²°ê³¼ í˜•ì‹**:
```json
{
  "content": [
    {
      "type": "text",
      "text": "{\"year\":\"2025\",\"totalEmission\":\"31.743\"}"
    }
  ],
  "isError": false
}
```

---

## ğŸ”„ ì „ì²´ ì‹¤í–‰ íë¦„

### ì‚¬ìš©ì ì§ˆë¬¸: "í›„ì‹œíŒŒíŠ¸ë„ˆìŠ¤111 íšŒì‚¬ì˜ 2025ë…„ ë°°ì¶œ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜"

```
1. ì‚¬ìš©ì ì…ë ¥
   â†“
2. LangGraph: call_model
   â”œâ”€> ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
   â”œâ”€> ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ (ê·œì œëŒ€ì‘)
   â”œâ”€> ìºì‹œ í™•ì¸ (ì—†ìŒ)
   â”œâ”€> Claude API í˜¸ì¶œ (22ê°œ ë„êµ¬ ì „ë‹¬)
   â””â”€> ì‘ë‹µ: tool_calls = [get_company_id_by_name]
   â†“
3. LangGraph: tools
   â”œâ”€> get_company_id_by_name ì‹¤í–‰
   â”‚   â”œâ”€> MCP í´ë¼ì´ì–¸íŠ¸ í™•ì¸ (ì—°ê²°ë¨)
   â”‚   â”œâ”€> POST /mcp/message (enterpriseName="í›„ì‹œíŒŒíŠ¸ë„ˆìŠ¤111")
   â”‚   â”œâ”€> SSEë¡œ ì‘ë‹µ ìˆ˜ì‹ 
   â”‚   â””â”€> ë°˜í™˜: 1
   â””â”€> ToolMessage(content=1)
   â†“
4. LangGraph: call_model
   â”œâ”€> ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ToolMessage ì¶”ê°€
   â”œâ”€> Claude API ì¬í˜¸ì¶œ
   â””â”€> ì‘ë‹µ: tool_calls = [get_total_emission]
   â†“
5. LangGraph: tools
   â”œâ”€> get_total_emission ì‹¤í–‰
   â”‚   â”œâ”€> MCP í´ë¼ì´ì–¸íŠ¸ í™•ì¸
   â”‚   â”œâ”€> POST /mcp/message (enterpriseId=1, year="2025")
   â”‚   â”œâ”€> SSEë¡œ ì‘ë‹µ ìˆ˜ì‹ 
   â”‚   â””â”€> ë°˜í™˜: {"totalEmission": "31.743", ...}
   â””â”€> ToolMessage(content={...})
   â†“
6. LangGraph: call_model
   â”œâ”€> ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ToolMessage ì¶”ê°€
   â”œâ”€> Claude API ì¬í˜¸ì¶œ
   â””â”€> ì‘ë‹µ: AIMessage (íˆ´ í˜¸ì¶œ ì—†ìŒ, ìµœì¢… ë‹µë³€)
        "í›„ì‹œíŒŒíŠ¸ë„ˆìŠ¤111ì˜ 2025ë…„ ì´ ë°°ì¶œëŸ‰ì€ 31.743 tCO2eqì…ë‹ˆë‹¤..."
   â†“
7. Mermaid ë³€í™˜ (ìˆìœ¼ë©´)
   â”œâ”€> ```mermaid ... ``` ê°ì§€
   â”œâ”€> kroki.io URL ìƒì„±
   â””â”€> ![ë‹¤ì´ì–´ê·¸ë¨](https://kroki.io/...)ë¡œ ë³€í™˜
   â†“
8. ìºì‹±
   â”œâ”€> LLM ì‘ë‹µ ìºì‹± (24ì‹œê°„)
   â””â”€> ë‹¤ìŒ ë™ì¼ ì§ˆë¬¸ ì‹œ ì¦‰ì‹œ ë°˜í™˜
   â†“
9. ì‚¬ìš©ìì—ê²Œ ìµœì¢… ë‹µë³€ ë°˜í™˜
```

---

## ğŸ’¡ í•µì‹¬ ê¸°ìˆ  ì •ë¦¬

### 1. **LangGraphì˜ ìƒíƒœ ê´€ë¦¬**
- `messages`: ëŒ€í™” íˆìŠ¤í† ë¦¬ (append-only)
- `add_messages`: ë©”ì‹œì§€ ID ê¸°ë°˜ ì—…ë°ì´íŠ¸
- `is_last_step`: recursion_limit ë„ë‹¬ ê°ì§€

### 2. **ReAct íŒ¨í„´**
```
Reasoning (ìƒê°) â†’ Action (ë„êµ¬ í˜¸ì¶œ) â†’ Observation (ê²°ê³¼) â†’ Reasoning â†’ ...
```

### 3. **MCP ì–‘ë°©í–¥ í†µì‹ **
- **ì†¡ì‹ **: POST `/mcp/message` (ëª…ë ¹)
- **ìˆ˜ì‹ **: SSE `/mcp/sse` (ì‘ë‹µ)
- **ë§¤ì¹­**: JSON-RPC IDë¡œ ìš”ì²­-ì‘ë‹µ ì—°ê²°

### 4. **RAG ê²€ìƒ‰ ìµœì í™”**
- LLM í‚¤ì›Œë“œ ì¶”ì¶œ
- í‚¤ì›Œë“œ + ì›ë³¸ ì´ì¤‘ ê²€ìƒ‰
- ìœ ì‚¬ë„ ì„ê³„ê°’ 0.5
- ì¤‘ë³µ ì œê±°
- ìºì‹±

### 5. **Mermaid ìë™ ë³€í™˜**
- zlib ì••ì¶• + base64 ì¸ì½”ë”©
- kroki.io API í™œìš©
- ì½”ë“œ ë¸”ë¡ â†’ ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€

### 6. **2ë‹¨ê³„ ìºì‹±**
- Redis (ë¶„ì‚° í™˜ê²½)
- Memory (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
- TTL 24ì‹œê°„
- ìºì‹œ í‚¤: SHA256 í•´ì‹œ

---

## ğŸ“Š ë„êµ¬ ëª©ë¡ (ì´ 22ê°œ)

### ê¸°ë³¸ ë„êµ¬ (3ê°œ)
1. `search` - Tavily ì›¹ ê²€ìƒ‰
2. `search_knowledge_base` - RAG ë²¡í„° ê²€ìƒ‰
3. `classify_customer_segment` - ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜

### NET-Z MCP ë„êµ¬ (19ê°œ)

#### ë°°ì¶œëŸ‰ ì¡°íšŒ
1. `get_total_emission` - ì´ ë°°ì¶œëŸ‰ ì¡°íšŒ
2. `get_emission_type_ratio` - ë°°ì¶œì¢…ë¥˜ ë¹„ìœ¨ ì¡°íšŒ
3. `get_scope_emission_comparison` - Scopeë³„ ë°°ì¶œëŸ‰ ë¹„êµ
4. `get_top10_facilities_by_scope` - Top 10 ì‹œì„¤ ì¡°íšŒ
5. `get_total_emission_comparison` - ì´ ë°°ì¶œëŸ‰ ë¹„êµ

#### ê³µí†µ ì½”ë“œ
6. `get_common_code` - ê³µí†µ ì½”ë“œ ì¡°íšŒ
7. `list_enum_keys` - Enum í‚¤ ëª©ë¡ ì¡°íšŒ

#### ëŒ€ì‹œë³´ë“œ
8. `get_dashboard_emission_comparison` - ëŒ€ì‹œë³´ë“œ ë°°ì¶œëŸ‰ ë¹„êµ
9. `get_dashboard_emission_type_ratio` - ëŒ€ì‹œë³´ë“œ ë°°ì¶œ ë¹„ìœ¨
10. `get_dashboard_input_status` - ëŒ€ì‹œë³´ë“œ ì…ë ¥ í˜„í™©

#### ë°°ì¶œí™œë™
11. `list_emission_activities` - ë°°ì¶œí™œë™ì› ëª©ë¡
12. `list_energy_by_activity` - í™œë™ë³„ ì—ë„ˆì§€ ëª©ë¡

#### ì—ë„ˆì§€
13. `get_energy_id_by_name` - ì—ë„ˆì§€ ID ì¡°íšŒ
14. `get_energy_info` - ì—ë„ˆì§€ ì •ë³´ ì¡°íšŒ
15. `get_energy_name_by_id` - ì—ë„ˆì§€ ì´ë¦„ ì¡°íšŒ
16. `list_all_energies` - ëª¨ë“  ì—ë„ˆì§€ ëª©ë¡

#### ê¸°ì—…
17. `get_company_id_by_name` - ê¸°ì—… ID ì¡°íšŒ
18. `get_company_name_by_id` - ê¸°ì—… ì´ë¦„ ì¡°íšŒ
19. `list_all_companies` - ëª¨ë“  ê¸°ì—… ëª©ë¡

---

## ğŸš€ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

### 1. ìºì‹± ì „ëµ
```python
# RAG ê²€ìƒ‰ ìºì‹± (24ì‹œê°„)
cached = cache_manager.get("rag", query)
if cached:
    return cached  # ë²¡í„° ê²€ìƒ‰ ìƒëµ

# LLM ì‘ë‹µ ìºì‹± (íˆ´ í˜¸ì¶œ ì—†ëŠ” ê²½ìš°ë§Œ)
if not response.tool_calls:
    cache_manager.set("llm", cache_key, response)
```

### 2. ì§€ì—° ë¡œë”©
```python
# ë²¡í„° ìŠ¤í† ì–´ ì§€ì—° ë¡œë”©
@property
def vectorstore(self):
    if self._vectorstore is None:
        self._vectorstore = Chroma(...)
    return self._vectorstore
```

### 3. ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
```python
# SSE ë¦¬ìŠ¤ë„ˆë¥¼ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
self.sse_task = asyncio.create_task(self._sse_listener())

# POST ìš”ì²­ê³¼ SSE ì‘ë‹µ ìˆ˜ì‹ ì„ ë³‘ë ¬ ì²˜ë¦¬
```

### 4. ìë™ ì¬ì—°ê²°
```python
# MCP í´ë¼ì´ì–¸íŠ¸ ìë™ ì¬ì—°ê²°
if not client.running or client.sse_task.done():
    client = await _get_mcp_client()  # ì¬ì´ˆê¸°í™”
```

---

## ğŸ”’ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µì›ë ¥

### 1. MCP ì—°ê²° ì‹¤íŒ¨
```python
try:
    result = await client.call_tool(tool_name, kwargs)
except Exception as e:
    if attempt < max_retries - 1:
        # í´ë¼ì´ì–¸íŠ¸ ì¬ì„¤ì • í›„ ì¬ì‹œë„
        _netz_mcp_client = None
        await asyncio.sleep(0.5)
    else:
        return f"ì˜¤ë¥˜: MCP ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)}"
```

### 2. SSE ì—°ê²° ëŠê¹€
```python
# SSE ë¦¬ìŠ¤ë„ˆ ìƒíƒœ ìë™ í™•ì¸ ë° ì¬ì‹œì‘
if not self.running or self.sse_task.done():
    self.running = True
    self.sse_task = asyncio.create_task(self._sse_listener())
```

### 3. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
```python
# Future ëŒ€ê¸° ì‹œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
result = await asyncio.wait_for(future, timeout=timeout)
```

---

## ğŸ“ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# Claude API
ANTHROPIC_API_KEY=sk-ant-api03-...

# LangSmith (ì„ íƒ)
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=lsv2_pt_...
LANGSMITH_PROJECT=ReAct-Agent-Template

# Tavily ê²€ìƒ‰
TAVILY_API_KEY=tvly-dev-...

# ìºì‹œ (ì„ íƒ)
USE_REDIS_CACHE=false
CACHE_TTL=86400
REDIS_URL=redis://localhost:6379/0

# NET-Z MCP
NETZ_MCP_URL=https://hooxi.shinssy.com
NETZ_MCP_ENABLED=true
```

---

## ğŸ¯ í•µì‹¬ íŠ¹ì§• ìš”ì•½

1. **ReAct íŒ¨í„´**: ìƒê° â†’ í–‰ë™ â†’ ê´€ì°° ë°˜ë³µ
2. **MCP í†µí•©**: 19ê°œ NET-Z ë„êµ¬ ìë™ ë¡œë“œ
3. **RAG ê²€ìƒ‰**: í•œêµ­ì–´ ì„ë² ë”© + í‚¤ì›Œë“œ ì¶”ì¶œ
4. **ì¹´í…Œê³ ë¦¬ë³„ ë‹µë³€**: íƒ„ì†Œë°°ì¶œê¶Œ/ê·œì œëŒ€ì‘/ê³ ê°ìƒë‹´
5. **Mermaid ìë™ ë³€í™˜**: ì½”ë“œ â†’ ì´ë¯¸ì§€
6. **2ë‹¨ê³„ ìºì‹±**: Redis + Memory
7. **ìë™ ì¬ì—°ê²°**: MCP í´ë¼ì´ì–¸íŠ¸ ë³µì›ë ¥
8. **ë¹„ë™ê¸° ì²˜ë¦¬**: asyncio ê¸°ë°˜ ê³ ì„±ëŠ¥

---

ì´ê²ƒì´ CarbonAI React-Agentì˜ ì „ì²´ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤! ğŸ‰
